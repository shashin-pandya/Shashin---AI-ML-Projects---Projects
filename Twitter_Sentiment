# -*- coding: utf-8 -*-
"""Twitter_Sentiment_v1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bOuuNlG0_zGtOQ-oFs8yvcgxl_zMxexU
"""

import pandas as pd
import numpy as np
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import re

import nltk
nltk.download('stopwords')


read_file = "C:/Users/Pash/Documents/Python_Scripts/Twitter Sentiment/Data/twitter.csv"
column_names = ['target','ids','date','flag','user','text',]
filo = pd.read_csv(read_file, names = column_names, encoding = "latin-1")
tweet_data = pd.DataFrame(filo)


tweet_data.isnull().sum()
tweet_data.replace({'target':{4:1}}, inplace=True)


port_stem = PorterStemmer()

def stemming(content):
  stemmed_content = re.sub('[^a-zA-Z]',' ',content)
  stemmed_content = stemmed_content.lower()
  stemmed_content = stemmed_content.split()
  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]
  stemmed_content = ' '.join(stemmed_content)

  return stemmed_content

tweet_data['stemmed_content'] = tweet_data['text'].apply(stemming)

tweet_data.head(10)

x = tweet_data['stemmed_content'].values
y = tweet_data['target'].values

x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, stratify=y, random_state=2)


vectorizer = TfidfVectorizer()
x_train = vectorizer.fit_transform(x_train)
x_test = vectorizer.transform(x_test)

model = LogisticRegression(max_iter=1000)

model.fit(x_train,y_train)

x_train_prediction = model.predict(x_train)
training_data_accuracy = accuracy_score(y_train, x_train_prediction)

print(training_data_accuracy)

x_test_prediction = model.predict(x_test)
test_data_accuracy = accuracy_score(y_test, x_test_prediction)

print(test_data_accuracy)

